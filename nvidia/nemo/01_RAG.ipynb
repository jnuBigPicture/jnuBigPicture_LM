{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYXCM0ED4BQM"
   },
   "source": [
    "## RAG (Retrieval Augmented Generation) 소개\n",
    "\n",
    "RAG는 LLM의 성능을 향상시키는 기술로, 외부 데이터를 활용해 정확성과 최신성을 높입니다. 사용자 질문에 관련된 정보를 검색하고 이를 LLM 입력에 추가하여 더 정확한 응답을 생성합니다.\n",
    "\n",
    "- RAG에 대한 설명:\n",
    "https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/\n",
    "- RAG 101: 검색 증강 생성 관련 질문과 답변:\n",
    "https://developer.nvidia.com/ko-kr/blog/rag-101-retrieval-augmented-generation-questions-answered/\n",
    "-\n",
    "RAG 파이프라인 구축 팁:\n",
    "https://developer.nvidia.com/blog/tips-for-building-a-rag-pipeline-with-nvidia-ai-langchain-ai-endpoints/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H2K9mg0kdHYs"
   },
   "source": [
    "#### LanghChain 소개\n",
    "\n",
    "LangChain은 LLM 기반 애플리케이션 개발을 위한 오픈소스 프레임워크입니다. 프롬프트 관리, 외부 데이터 연결, 메모리 기능 등을 제공하여 개발 과정을 간소화하고 다양한 LLM과의 통합을 지원합니다.\n",
    "\n",
    "- LangChain 소개: https://python.langchain.com/v0.2/docs/introduction/\n",
    "- NVIDIA와 LangChain이 진행하는 생성형 AI 에이전트 개발자 컨테스트:\n",
    "https://www.nvidia.com/ko-kr/ai-data-science/generative-ai/developer-contest-with-langchain/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3a-tZVyQ5T4-"
   },
   "source": [
    "\n",
    "### 환경설정\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1R4yN1FUaU0"
   },
   "source": [
    "#### LangChain 과 결합된 NVIDIA NIM 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8909,
     "status": "ok",
     "timestamp": 1721029100659,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "LkrREkzvgLjm",
    "outputId": "684213e1-21a0-489d-9c4a-2933e8a3a4a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain_nvidia_ai_endpoints\n",
      "  Downloading langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from langchain_nvidia_ai_endpoints) (3.9.3)\n",
      "Collecting langchain-core<0.4,>=0.3.0 (from langchain_nvidia_ai_endpoints)\n",
      "  Downloading langchain_core-0.3.18-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: pillow<11.0.0,>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain_nvidia_ai_endpoints) (10.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (4.0.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (6.0.1)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints)\n",
      "  Downloading langsmith-0.1.143-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (23.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.8.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (4.12.2)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.27.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints)\n",
      "  Downloading orjson-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.32.3)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2.20.1)\n",
      "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints) (3.6)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (4.4.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.26.19)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3.0->langchain_nvidia_ai_endpoints) (1.2.0)\n",
      "Downloading langchain_nvidia_ai_endpoints-0.3.5-py3-none-any.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 kB\u001b[0m \u001b[31m189.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.18-py3-none-any.whl (409 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.3/409.3 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.143-py3-none-any.whl (306 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m249.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.10.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m235.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m208.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, orjson, jsonpointer, requests-toolbelt, jsonpatch, langsmith, langchain-core, langchain_nvidia_ai_endpoints\n",
      "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.18 langchain_nvidia_ai_endpoints-0.3.5 langsmith-0.1.143 orjson-3.10.11 requests-toolbelt-1.0.0 tenacity-9.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_nvidia_ai_endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JruB8Ig1U31V"
   },
   "source": [
    "#### LangChain 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16017,
     "status": "ok",
     "timestamp": 1721025639611,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "Tg50c1dcHiz8",
    "outputId": "74d0fc44-66bd-4049-efd9-ee920523a329"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting langchain-text-splitters\n",
      "  Downloading langchain_text_splitters-0.3.2-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
      "Collecting SQLAlchemy<2.0.36,>=1.4 (from langchain-community)\n",
      "  Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting langchain<0.4.0,>=0.3.7 (from langchain-community)\n",
      "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.17 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.18)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.24.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.6.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.7->langchain-community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.17->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.0.3)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.17->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.7->langchain-community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.0)\n",
      "Downloading langchain_community-0.3.7-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.2-py3-none-any.whl (25 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.7-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m261.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.6.1-py3-none-any.whl (28 kB)\n",
      "Downloading SQLAlchemy-2.0.35-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m254.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: SQLAlchemy, python-dotenv, httpx-sse, dataclasses-json, pydantic-settings, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed SQLAlchemy-2.0.35 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-0.3.7 langchain-community-0.3.7 langchain-text-splitters-0.3.2 pydantic-settings-2.6.1 python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community langchain-text-splitters faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IznNzOLZVHL0"
   },
   "source": [
    "#### Embedding 모델을 위한 sentence-transformers 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 79022,
     "status": "ok",
     "timestamp": 1721026059220,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "rbmOT-3mI9La",
    "outputId": "095a2d8b-fefe-434c-e35f-f784327f0359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.3.0a0+40ec155e58.nv24.3)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.12.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.23.4)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kMYu5NHVBis"
   },
   "source": [
    "#### vector DB를 위한 chromadb 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34815,
     "status": "ok",
     "timestamp": 1721028009349,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "zZXgrzAKQrTC",
    "outputId": "8df3df3e-7533-417a-b40e-0641e5ca0e7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.18-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.24.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.7.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.28.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.4)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.5-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.65.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.4)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (30.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.11)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.0)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.7.1)\n",
      "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (4.4.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.6)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.28.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.26.19)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (7.0.2)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.28.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.28.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-util-http==0.49b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.49b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.49b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.17.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.7.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kubernetes>=28.1.0->chromadb) (3.3.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Downloading chromadb-0.5.18-py3-none-any.whl (615 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.2.0-cp39-abi3-manylinux_2_28_x86_64.whl (273 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m218.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m222.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.28.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m230.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.28.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.28.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.28.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m213.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.49b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.49b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.49b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.49b1-py3-none-any.whl (159 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.2/159.2 kB\u001b[0m \u001b[31m242.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.49b1-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.28.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m239.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.7.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m178.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m203.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.7/221.7 kB\u001b[0m \u001b[31m244.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m244.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading protobuf-5.28.3-cp38-abi3-manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.6/316.6 kB\u001b[0m \u001b[31m257.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m221.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m134.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-0.24.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (425 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m425.7/425.7 kB\u001b[0m \u001b[31m262.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading websockets-14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.2/168.2 kB\u001b[0m \u001b[31m261.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=933554704558b3a536d9bb50705f0c5f88639ee195472c2df916588b0fb7de3a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-tv13ecy4/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, flatbuffers, websockets, uvloop, uvicorn, protobuf, overrides, opentelemetry-util-http, mmh3, importlib-resources, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-proto, opentelemetry-api, onnxruntime, googleapis-common-protos, opentelemetry-semantic-conventions, opentelemetry-exporter-otlp-proto-common, fastapi, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.20.3\n",
      "    Uninstalling protobuf-3.20.3:\n",
      "      Successfully uninstalled protobuf-3.20.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.2.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.2.2 which is incompatible.\n",
      "cudf 24.2.0 requires protobuf<5,>=4.21, but you have protobuf 5.28.3 which is incompatible.\n",
      "cugraph 24.2.0 requires dask-cuda==24.2.*, but you have dask-cuda 24.6.0 which is incompatible.\n",
      "cugraph 24.2.0 requires rapids-dask-dependency==24.2.*, but you have rapids-dask-dependency 24.6.0 which is incompatible.\n",
      "cugraph-service-server 24.2.0 requires dask-cuda==24.2.*, but you have dask-cuda 24.6.0 which is incompatible.\n",
      "cugraph-service-server 24.2.0 requires rapids-dask-dependency==24.2.*, but you have rapids-dask-dependency 24.6.0 which is incompatible.\n",
      "cuml 24.2.0 requires dask-cuda==24.2.*, but you have dask-cuda 24.6.0 which is incompatible.\n",
      "cuml 24.2.0 requires rapids-dask-dependency==24.2.*, but you have rapids-dask-dependency 24.6.0 which is incompatible.\n",
      "cuml 24.2.0 requires treelite==4.0.0, but you have treelite 4.1.2 which is incompatible.\n",
      "dask-cudf 24.2.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.2.2 which is incompatible.\n",
      "dask-cudf 24.2.0 requires rapids-dask-dependency==24.2.*, but you have rapids-dask-dependency 24.6.0 which is incompatible.\n",
      "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 5.28.3 which is incompatible.\n",
      "tensorrt-llm 0.10.0 requires nvidia-modelopt<0.12,~=0.11, but you have nvidia-modelopt 0.0.0 which is incompatible.\n",
      "tensorrt-llm 0.10.0 requires pynvml>=11.5.0, but you have pynvml 11.4.1 which is incompatible.\n",
      "wandb 0.16.6 requires protobuf!=4.21.0,<5,>=3.19.0; python_version > \"3.9\" and sys_platform == \"linux\", but you have protobuf 5.28.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 chroma-hnswlib-0.7.6 chromadb-0.5.18 deprecated-1.2.14 fastapi-0.115.5 flatbuffers-24.3.25 googleapis-common-protos-1.66.0 httptools-0.6.4 importlib-resources-6.4.5 mmh3-5.0.1 monotonic-1.6 onnxruntime-1.20.0 opentelemetry-api-1.28.1 opentelemetry-exporter-otlp-proto-common-1.28.1 opentelemetry-exporter-otlp-proto-grpc-1.28.1 opentelemetry-instrumentation-0.49b1 opentelemetry-instrumentation-asgi-0.49b1 opentelemetry-instrumentation-fastapi-0.49b1 opentelemetry-proto-1.28.1 opentelemetry-sdk-1.28.1 opentelemetry-semantic-conventions-0.49b1 opentelemetry-util-http-0.49b1 overrides-7.7.0 posthog-3.7.0 protobuf-5.28.3 pypika-0.48.9 starlette-0.41.2 uvicorn-0.32.0 uvloop-0.21.0 watchfiles-0.24.0 websockets-14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vZHib_35qBX"
   },
   "source": [
    "### NIM 컨테이너 배포\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zYoRudwAzDk"
   },
   "source": [
    "NGC 리소스에 액세스하려면 NGC API 키가 필요하며 https://org.ngc.nvidia.com/setup/personal-keys 에서 키를 생성할 수 있습니다. NGC API 키를 생성할 때 \"Services included\" 드롭다운에서 최소한 \"NGC Catalog\"가 선택되어 있는지 확인하세요. 이 키를 다른 목적으로 재사용하려면 더 많은 서비스가 포함될 수 있습니다.\n",
    "```\n",
    "export NGC_API_KEY=<value>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2SuVxID5b7O"
   },
   "source": [
    "```python\n",
    "import os\n",
    "\n",
    "# NIM 컨테이너 배포\n",
    "container_name = \"llama3-70b-instruct\"\n",
    "img_name = f\"nvcr.io/nim/{container_name}:1.0.0\"\n",
    "local_nim_cache = \"~/.cache/nim\"\n",
    "\n",
    "!mkdir -p {local_nim_cache}\n",
    "!docker run -d --name={container_name} \\\n",
    "    --runtime=nvidia \\\n",
    "    --gpus all \\\n",
    "    -e NGC_API_KEY \\\n",
    "    -v {local_nim_cache}:/opt/nim/.cache \\\n",
    "    -u $(id -u) \\\n",
    "    -p 8000:8000 \\\n",
    "    {img_name}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhqWn7c99vy"
   },
   "source": [
    "### NIM base URL (http://Ip:port) 입력 받기\n",
    "\n",
    "예) http://0.0.0.0:8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VLAe7ZcH99OA"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NIM URL을 입력하세요 http://0.0.0.0:8000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_url = input(\"NIM URL을 입력하세요\")\n",
    "\n",
    "os.environ[\"NIM_URL\"] = base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1721023622236,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "A_yNwbQK6LCE",
    "outputId": "75715818-cd0c-4e8e-d71d-8a8781b334e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chat-cc99bf00c1864d358c162ff2f26edd21\",\"object\":\"chat.completion\",\"created\":1731588310,\"model\":\"meta/llama-3.1-70b-instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"There once was a GPU so fine,\\nWhose computing power did truly shine.\\nIt processed with pace,\\nLarge datasets with ease and space,\\nAnd calculations that were truly divine.\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":23,\"total_tokens\":58,\"completion_tokens\":35}}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "\"$NIM_URL/v1/chat/completions\" \\\n",
    "-H 'accept: application/json' \\\n",
    "-H 'Content-Type: application/json' \\\n",
    "-d '{ \\\n",
    "    \"model\": \"meta/llama-3.1-70b-instruct\", \\\n",
    "    \"messages\": [{\"role\":\"user\", \"content\":\"Write a limerick about the wonders of GPU computing.\"}],\\\n",
    "    \"max_tokens\": 64 \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCSx_UMG8lZ9"
   },
   "source": [
    "### OpenAI API interface 사용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_R3Z2GoYJimL"
   },
   "source": [
    "### 한국어 임베딩 모델 사용 (https://huggingface.co/jhgan/ko-sroberta-multitask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "642-1J4kQTc9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "import multiprocessing\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SkZx8-J0JBkL"
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yTAS9GI-VXph"
   },
   "source": [
    "#### 웹피이지 URL 리스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "kS7q6KY3TtLO"
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "        \"https://developer.nvidia.com/ko-kr/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/\",\n",
    "        \"https://blogs.nvidia.co.kr/blog/nvidia-announces-major-updates-to-triton-inference-server-as-25-000-companies-worldwide-deploy-nvidia-ai-inference/\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "79zG8vz-ViZ7"
   },
   "source": [
    "#### 웹피이지 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lz45JqUdVhQ1"
   },
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mu3zc99aVlPp"
   },
   "source": [
    "#### 텍스트 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "sk73gksRT6Vi"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVDZXn6fVrCr"
   },
   "source": [
    "#### 임베딩 생성 및 벡터 저장소 생성\n",
    "- 한국어 임베딩 모델 사용 (https://huggingface.co/jhgan/ko-sroberta-multitask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17484,
     "status": "ok",
     "timestamp": 1721028873255,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "p_EUitGGhOwo",
    "outputId": "f03ac379-6fea-424d-cc16-81a26625fd04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8402/2802534561.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 463,
     "status": "ok",
     "timestamp": 1721029423968,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "kYVg9EOkRiP7",
    "outputId": "4a1ac359-0280-41f1-95ac-92e60b823c55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_nvidia_ai_endpoints/_common.py:237: UserWarning: Default model is set as: meta/llama-3.1-70b-instruct. \n",
      "Set model using model parameter. \n",
      "To get available models use available_models property.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = ChatNVIDIA(base_url=\"{0}/v1\".format(os.environ[\"NIM_URL\"]), api_key=\"not-used\",temperature= 0.9,top_p= 1,max_token=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HEkFKCIBWaMc"
   },
   "source": [
    "#### 프롬프트 템플릿 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "fEE4Dx_rSZYN"
   },
   "outputs": [],
   "source": [
    "template = \"\"\"다음은 사용자의 질문에 대한 vector DB 검색 결과입니다. 이 정보를 바탕으로 질문에 답변해 주세요.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "Retreiver 결과:\n",
    "{context}\n",
    "\n",
    "위의 정보를 바탕으로 사용자의 질문에 대해 명확하고 정확하게 답변해 주세요. 검색 결과에 없는 정보는 추측하지 말고, 모르는 경우 솔직히 모른다고 답변하세요.\n",
    "Anaswer should be Korean\n",
    "답변:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "QCdvajp8Sl6m"
   },
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\n",
    "    \"prompt\": prompt,\n",
    "    \"document_variable_name\": \"context\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_y4RLKqWfHJ"
   },
   "source": [
    "#### RAG 파이프라인 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8DrC32IxROkE"
   },
   "outputs": [],
   "source": [
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    chain_type_kwargs=chain_type_kwargs,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83562,
     "status": "ok",
     "timestamp": 1721029762060,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "tCACpH4bWn3a",
    "outputId": "332a4455-68b5-4a4b-9ca4-6a14797dd018"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  TensorRT-LLM에 대해서 알려줘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8402/1583497270.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": user_input})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: NVIDIA TensorRT-LLM은 NVIDIA의 인공 지능(AI) 소프트웨어 프레임워크인 TensorRT와 큰 언어 모델(LLM)을 사용하여 성능을 강화하는 기술입니다.\n",
      "\n",
      "NVIDIA TensorRT-LLM은 Meta의 Llama 3.2 모델을 사용하여 Edge에서 Cloud까지 가속화된 Llama 3.2 배포하기를 구현하였고, Writer, 의료 및 금융을 위한 도메인별 LLM 출시하였습니다. 또한 NVIDIA TensorRT-LLM 및 NVIDIA Triton Inference Server로 Meta Llama 3 성능 강화와 8-bit 포스트 트레이닝 양자화로 안정적인 확산을 2배 더 빠르게 가속화하는 등의 업그레이드된 NVIDIA TensorRT 10.0의 사용성, 성능, AI 모델 지원을 제공합니다.\n",
      "참조 문서: [Document(metadata={'description': '빠르게 진화하는 생성형 AI 환경에서 가속화된 추론 속도에 대한 요구는 여전히 시급한 문제입니다. 모델 크기와 복잡성이 기하급수적으로 증가함에 따라…', 'language': 'ko-KR', 'source': 'https://developer.nvidia.com/ko-kr/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/', 'title': 'NVIDIA TensorRT Model Optimizer로 생성형 AI 추론 성능 가속화 - NVIDIA Technical Blog'}, page_content='Discuss (0)\\n        \\n\\n\\n  \\n\\n      Like    \\n\\n\\n\\n\\nTags\\n\\n\\nGenerative AI | General | Academia / Education | Aerospace | Agriculture | Architecture / Engineering / Construction | Automotive / Transportation | Cloud Services | Consumer Internet | Energy | Financial Services | Gaming | Hardware / Semiconductor | Healthcare & Life Sciences | HPC / Scientific Computing | Manufacturing | Media & Entertainment | Public Sector | Restaurant / Quick-Service | Retail / Consumer Packaged Goods | Smart Cities / Spaces | Telecommunications | A100 | TensorRT | Intermediate Technical | Deep dive | AI Inference | featured | LLMs | Stable Diffusion | TensorRT-LLM \\n\\n\\n\\n\\n\\n                작성자 소개\\n              \\n\\n\\n\\n\\n\\n\\n\\n                  Erin Ho 프로필'), Document(metadata={'description': '빠르게 진화하는 생성형 AI 환경에서 가속화된 추론 속도에 대한 요구는 여전히 시급한 문제입니다. 모델 크기와 복잡성이 기하급수적으로 증가함에 따라…', 'language': 'ko-KR', 'source': 'https://developer.nvidia.com/ko-kr/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/', 'title': 'NVIDIA TensorRT Model Optimizer로 생성형 AI 추론 성능 가속화 - NVIDIA Technical Blog'}, page_content='댓글\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n관련 게시물\\n\\n\\n\\n\\n\\n\\n\\n\\n          엣지에서 클라우드로 가속화된 Llama 3.2 배포하기\\n        \\n\\n\\n\\n엣지에서 클라우드로 가속화된 Llama 3.2 배포하기\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          Writer, 의료 및 금융을 위한 도메인별 LLM 출시\\n        \\n\\n\\n\\nWriter, 의료 및 금융을 위한 도메인별 LLM 출시\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          업그레이드된 NVIDIA TensorRT 10.0의 사용성, 성능, AI 모델 지원\\n        \\n\\n\\n\\n업그레이드된 NVIDIA TensorRT 10.0의 사용성, 성능, AI 모델 지원\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          NVIDIA TensorRT-LLM 및 NVIDIA Triton Inference Server로 Meta Llama 3 성능 강화\\n        \\n\\n\\n\\nNVIDIA TensorRT-LLM 및 NVIDIA Triton Inference Server로 Meta Llama 3 성능 강화\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n          8-bit 포스트 트레이닝 양자화로 안정적인 확산을 2배 더 빠르게 가속화하는 NVIDIA TensorRT\\n        \\n\\n\\n\\n8-bit 포스트 트레이닝 양자화로 안정적인 확산을 2배 더 빠르게 가속화하는 NVIDIA TensorRT\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nL\\nT\\nF\\nR\\nE'), Document(metadata={'description': '빠르게 진화하는 생성형 AI 환경에서 가속화된 추론 속도에 대한 요구는 여전히 시급한 문제입니다. 모델 크기와 복잡성이 기하급수적으로 증가함에 따라…', 'language': 'ko-KR', 'source': 'https://developer.nvidia.com/ko-kr/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/', 'title': 'NVIDIA TensorRT Model Optimizer로 생성형 AI 추론 성능 가속화 - NVIDIA Technical Blog'}, page_content='NVIDIA TensorRT Model Optimizer로 생성형 AI 추론 성능 가속화 - NVIDIA Technical Blog\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDEVELOPER\\n\\n\\n\\n홈블로그포럼문서다운로드교육과정\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n검색하기\\n\\n\\n\\n\\n\\nJoin\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n    Related Resources \\n\\n\\n\\n\\n\\n\\n\\n\\nGenerative AI\\n\\n\\n\\nEnglish한국어\\n\\n\\nNVIDIA TensorRT Model Optimizer로 생성형 AI 추론 성능 가속화\\n\\n\\n            2024년 5월 17일\\n          \\n\\n            By Erin Ho, Chenjie Luo, Di Wu and Ashraf Eassa \\n\\n\\n  \\n\\n                Like              \\n\\n\\n\\n Discuss (0)'), Document(metadata={'description': '빠르게 진화하는 생성형 AI 환경에서 가속화된 추론 속도에 대한 요구는 여전히 시급한 문제입니다. 모델 크기와 복잡성이 기하급수적으로 증가함에 따라…', 'language': 'ko-KR', 'source': 'https://developer.nvidia.com/ko-kr/blog/accelerate-generative-ai-inference-performance-with-nvidia-tensorrt-model-optimizer-now-publicly-available/', 'title': 'NVIDIA TensorRT Model Optimizer로 생성형 AI 추론 성능 가속화 - NVIDIA Technical Blog'}, page_content='그래픽 카드INT8 지연 시간(ms)FP8 지연 시간(ms)속도 향상(INT8 vs FP16)속도 향상(FP8 vs FP16)RTX 6000 Ada2,4792,4411.43배1.45배RTX 40902,0582,1611.20배1.14배L40S2,3392,1681.25배1.35배H100 80GB HBM31,2091,2161.08배1.07배표 1. 배포를 위해 Model Optimizer 및 TensorRT의 8비트 PTQ를 사용하여 다양한 NVIDIA 하드웨어에 걸쳐 SDXL의 추론 속도 향상\\n구성: Stable Diffusion XL 1.0 기본 모델. 이미지 해상도 = 1024×1024, 30단계. TensorRT v9.3. 배치 크기=1')]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  NVIDIA NIM에 대해서 설명 해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "답변: NVIDIA NIM은 NVIDIA의 AI 추론 플랫폼으로, NVIDIA Triton Inference Server와 Tensor RT를 지원합니다. Triton Inference Server는 모든 AI 모델과 프레임워크에 대한 교차 플랫폼 추론을 제공하는 오픈소스 소프트웨어입니다. Tensor RT는 AI 모델을 최적화하고, NVIDIA GPU의 고성능 추론을 위한 런타임을 제공합니다.\n",
      "참조 문서: [Document(metadata={'description': 'NVIDIA는 전세계 25,000명 이상의 고객들이 사용하는 AI 추론 플랫폼인 NVIDIA Triton Inference Server의 최신 업데이트를 발표했습니다!', 'language': 'ko-KR', 'source': 'https://blogs.nvidia.co.kr/blog/nvidia-announces-major-updates-to-triton-inference-server-as-25-000-companies-worldwide-deploy-nvidia-ai-inference/', 'title': '고성능 AI 추론이 가능한 NVIDIA Triton 최신 업데이트 소식! | NVIDIA Blog'}, page_content='글로벌 엔터프라이즈 시스템 제공업체인 아토스(Atos), 델 테크놀로지스(Dell Technologies), 기가바이트(GIGABYTE), 휴렛 팩커드 엔터프라이즈(Hewlett Packard Enterprise), 인스퍼(Inspur), 레노버(Lenovo) 및 슈퍼마이크로(Supermicro)는 AI 시스템 포트폴리오에서 NVIDIA-Certified Systems을 통해 NVIDIA AI Enterprise를 지원합니다.\\n이 밖에도 어드밴텍(Adventech), 애즈락랙(ASRock Rack), 에이수스(ASUS), H3C, 넷트릭스(Nettrix), QCT와 같은 추가적인 시스템 공급사에서도 다양한 워크로드를 위해 NVIDIA-Certified Systems을 제공하는데요. 최초로 NVIDIA-Certified Systems을 통과한 엣지 카테고리는 어드밴텍, 기가바이트, 레노버를 포함한 선도 제공업체에서 곧 출시될 예정입니다.\\n출시 일정에 대하여\\nTriton은 프레임워크, 툴킷, 사전 훈련 모델과 주피터 노트북(Jupyter Notebooks)을 포함하는 GPU 최적화 AI 소프트웨어 허브인 NVIDIA NGC 카탈로그와 트리톤 깃허브 리포지토리(Triton GitHub repository)에서 오픈 소스 코드로 이용할 수 있습니다.\\nTensor RT는 Tensor RT 페이지에서 NVIDIA 개발자 프로그램 회원을 대상으로 제공됩니다. 최신 버전의 플러그인, 파서(parsers), 샘플도 Tensor RT 깃허브 리포지토리에서 오픈 소스로 제공됩니다.\\nNVIDIA 고객은 전 세계에 제공되는 NVIDIA LaunchPad의 큐레이티드 랩을 통해 NVIDIA AI Enterprise 소프트웨어 제품군의 NVIDIA Triton을 이용할 수 있습니다.'), Document(metadata={'description': 'NVIDIA는 전세계 25,000명 이상의 고객들이 사용하는 AI 추론 플랫폼인 NVIDIA Triton Inference Server의 최신 업데이트를 발표했습니다!', 'language': 'ko-KR', 'source': 'https://blogs.nvidia.co.kr/blog/nvidia-announces-major-updates-to-triton-inference-server-as-25-000-companies-worldwide-deploy-nvidia-ai-inference/', 'title': '고성능 AI 추론이 가능한 NVIDIA Triton 최신 업데이트 소식! | NVIDIA Blog'}, page_content='NVIDIA 고객은 전 세계에 제공되는 NVIDIA LaunchPad의 큐레이티드 랩을 통해 NVIDIA AI Enterprise 소프트웨어 제품군의 NVIDIA Triton을 이용할 수 있습니다.\\nNVIDIA AI Enterprise 소프트웨어 제품군은 Atea, 액시언즈(Axians), 캐러소프트 데크놀로지 코퍼레이션(Carahsoft Technology Corp.), 컴퓨터센터(Computacenter), 인사이트 엔터프라이즈(Insight Enterprise), 프레시디오(Presidio), 시리우스(Sirius), 소프트서브(SoftServe), SVA 시스템 버트리브 알렉산더 GmbH(SVA System Vertrieb Alexander GmbH), TD 시넥스(TD SYNNEX), 트레이스(Trace)3와 월드와이트테크놀로지(World Wide Technology)를 포함하여 전세계 NVIDIA 파트너로부터 제공됩니다.'), Document(metadata={'description': 'NVIDIA는 전세계 25,000명 이상의 고객들이 사용하는 AI 추론 플랫폼인 NVIDIA Triton Inference Server의 최신 업데이트를 발표했습니다!', 'language': 'ko-KR', 'source': 'https://blogs.nvidia.co.kr/blog/nvidia-announces-major-updates-to-triton-inference-server-as-25-000-companies-worldwide-deploy-nvidia-ai-inference/', 'title': '고성능 AI 추론이 가능한 NVIDIA Triton 최신 업데이트 소식! | NVIDIA Blog'}, page_content='카테고리: AI | Deep Learning | Corporate | Deep Learning태그: Artificial Intelligence | GTC 2021 | Inference | Machine Learning | TensorRT | Triton | Triton Inference Server \\n\\n\\nAll NVIDIA News \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t‘NVIDIA AI와 Omniverse’로 미래를 재정의하고 있는 일본 기업들\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t일본의 의료 분야 혁신 속도 높이는 NVIDIA 기술\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\tNVIDIA 가속 컴퓨팅과 함께 AI 혁신 강화하는 일본 스타트업\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t‘NVIDIA NIM 웨비나’, 쉽고 빠르게 생성형 AI 모델의 정확도를 높일 수 있는 기회!\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t모든 산업에서 AI로 방대한 시각적 데이터를 검색하고 요약할 수 있는 시대가 열렸습니다.\\t\\t\\t\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n\\n\\nPost navigation\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n솔루션\\n그래픽카드\\nGRID\\n고성능 컴퓨팅\\n비주얼라이제이션\\nCUDA\\n배경화면\\n \\n\\nCorporate\\n이벤트\\n협력 프로그램\\n개발자\\nNVIDIA  파트너 네트워크\\n채용 정보\\nRSS  피드\\n뉴스레터 구독\\n문의하기\\n보안\\n \\n\\nFooter Links\\n법적 정보\\n개인정보 보호정책\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\t\\t\\t지역별 블로그와 다른 소셜 네트워크를 탐색해 보세요.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n개인정보보호정책\\n내 개인정보 관리\\n내 데이터 판매 또는 공유 금지\\n서비스 약관\\n접근성\\n기업 정책\\n제품 보안\\n연락처\\n \\n\\t\\t\\tCopyright © 2024 NVIDIA Corporation \\t\\t\\n\\n\\n\\n\\n\\t\\t\\t\\tKorea\\t\\t\\t\\t\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nEmail sent!'), Document(metadata={'description': 'NVIDIA는 전세계 25,000명 이상의 고객들이 사용하는 AI 추론 플랫폼인 NVIDIA Triton Inference Server의 최신 업데이트를 발표했습니다!', 'language': 'ko-KR', 'source': 'https://blogs.nvidia.co.kr/blog/nvidia-announces-major-updates-to-triton-inference-server-as-25-000-companies-worldwide-deploy-nvidia-ai-inference/', 'title': '고성능 AI 추론이 가능한 NVIDIA Triton 최신 업데이트 소식! | NVIDIA Blog'}, page_content='Home\\n데이터센터\\n자율주행 자동차\\n게이밍\\n전문가용 그래픽\\n오토노머스 머신\\n헬스케어\\n스타트업\\n \\n\\n \\n\\n\\n\\n\\n\\n\\n\\n\\n고성능 AI 추론이 가능한 NVIDIA Triton 최신 업데이트 소식!\\n\\n11월 10, 2021 by NVIDIA Korea \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\t\\t\\t\\t\\tShare\\t\\t\\t\\n\\n\\n \\n \\n \\nEmail \\n\\n\\n  NVIDIA는 전세계 25,000명 이상의 고객들이 사용하는 AI 추론 플랫폼인 NVIDIA Triton Inference Server의 최신 업데이트를 발표했습니다!\\nTriton Inference Server는 캐피탈 원(Capital One), 마이크로소프트(Microsoft), 지멘스 에너지(Siemens Energy), 스냅(Snap)을 비롯해 수많은 고객들이 사용 중인데요. 이번 업데이트는 모든 AI 모델과 프레임워크에 대한 교차 플랫폼 추론을 제공하는 오픈소스 NVIDIA Triton Inference Server 소프트웨어와 AI 모델을 최적화하고, NVIDIA GPU의 고성능 추론을 위한 런타임을 제공하는 Tensor RT를 지원합니다.\\n또한 NVIDIA는 CPU보다 최대 20배 더 높은 추론 성능을 제공하는 AI 추론용 저전력 소형 가속기인 NVIDIA A2 Tensor Core GPU를 선보였습니다.\\nNVIDIA 가속 컴퓨팅 담당 부사장 겸 총괄 매니저인 이안 벅(Ian Buck)은 “NVIDIA의 AI 추론 플랫폼은 헬스케어, 금융 서비스, 소매, 제조와 슈퍼컴퓨팅을 포함한 거의 모든 산업에 걸쳐 돌파구를 마련하고 있습니다. NVIDIA의 추론 플랫폼은 스마트한 추천 기능과 대화용 AI의 성능을 활용하거나 과학적 발견을 촉진함에 있어 전세계 최신 및 주요 AI 애플리케이션을 지원하는 데 필요한 사용 편의성, 저 지연시간, 높은 처리량, 다양한 성능을 제공합니다”라고 강조했습니다.\\n주요 소프트웨어 최적화\\nTriton Inference Server에 대한 업데이트는 아래와 같습니다.')]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"사용자: \")\n",
    "\n",
    "    if user_input.lower() == 'quit':\n",
    "        print(\"종료합니다. 감사합니다!\")\n",
    "        break\n",
    "\n",
    "    result = qa_chain({\"query\": user_input})\n",
    "    print(\"답변:\", result[\"result\"])\n",
    "    print(\"참조 문서:\", result[\"source_documents\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_yVahJlTKky"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPsdL5PQbAJ8Ko0Grc7jbI7",
   "provenance": [
    {
     "file_id": "1_iP4TeSrdmBvZpQAufFNdAGDInHEk0d6",
     "timestamp": 1721024860356
    },
    {
     "file_id": "1KdsI5tQdlH0RLEd2ojGhX6Ao3OqMxYKx",
     "timestamp": 1721021419964
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
