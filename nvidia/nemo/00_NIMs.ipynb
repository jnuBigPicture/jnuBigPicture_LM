{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZYXCM0ED4BQM"
   },
   "source": [
    "## NVIDIA NIM (NVIDIA Inference Microservices) 소개\n",
    "NVIDIA NIM (NVIDIA Inference Microservices)은 엔터프라이즈급 생성형 AI 모델 배포를 위한 강력한 추론 마이크로 플랫폼입니다. 이 혁신적인 도구는 기업과 개발자들이 대규모 언어 모델 (LLM)과 같은 복잡한 AI 모델을 쉽고 효율적으로 배포하고 관리할 수 있도록 설계되었습니다.\n",
    "- [NVIDIA NIM 개발자 페이지](https://developer.nvidia.com/nim)\n",
    "- [NVIDIA API 카탈로그](https://build.nvidia.com/explore/discover)\n",
    "- [NVIDIA NIM 소개 블로그 (한국어)](https://blogs.nvidia.co.kr/blog/nvidia-nim-model-deployment-generative-ai-developers/)\n",
    "- [NVIDIA NIM 출시 뉴스](https://nvidianews.nvidia.com/news/nvidia-nim-model-deployment-generative-ai-developers)\n",
    "- [How to self-host and hyperscale AI with Nvidia NIM - YouTube](https://www.youtube.com/watch?v=ZgGss27IfwA)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WQ1Fj74AF1YQ",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.7.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vZHib_35qBX"
   },
   "source": [
    "### NIM 컨테이너 배포\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zYoRudwAzDk"
   },
   "source": [
    "NGC 리소스에 액세스하려면 NGC API 키가 필요하며 https://org.ngc.nvidia.com/setup/personal-keys 에서 키를 생성할 수 있습니다. NGC API 키를 생성할 때 \"Services included\" 드롭다운에서 최소한 \"NGC Catalog\"가 선택되어 있는지 확인하세요. 이 키를 다른 목적으로 재사용하려면 더 많은 서비스가 포함될 수 있습니다.\n",
    "```\n",
    "export NGC_API_KEY=<value>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o2SuVxID5b7O"
   },
   "source": [
    "```python\n",
    "import os\n",
    "\n",
    "# NIM 컨테이너 배포\n",
    "container_name = \"llama3-70b-instruct\"\n",
    "img_name = f\"nvcr.io/nim/{container_name}:1.0.0\"\n",
    "local_nim_cache = \"~/.cache/nim\"\n",
    "\n",
    "!mkdir -p {local_nim_cache}\n",
    "!docker run -d --name={container_name} \\\n",
    "    --runtime=nvidia \\\n",
    "    --gpus all \\\n",
    "    -e NGC_API_KEY \\\n",
    "    -v {local_nim_cache}:/opt/nim/.cache \\\n",
    "    -u $(id -u) \\\n",
    "    -p 8000:8000 \\\n",
    "    {img_name}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijhqWn7c99vy"
   },
   "source": [
    "### NIM base URL (http://Ip:port) 입력 받기\n",
    "\n",
    "예) http://0.0.0.0:8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VLAe7ZcH99OA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "NIM URL을 입력하세요 http://0.0.0.0:8000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "base_url = input(\"NIM URL을 입력하세요\")\n",
    "\n",
    "os.environ[\"NIM_URL\"] = base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 585,
     "status": "ok",
     "timestamp": 1721023622236,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "A_yNwbQK6LCE",
    "outputId": "75715818-cd0c-4e8e-d71d-8a8781b334e1",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chat-ba3592228e2847ce91867a01290c8d30\",\"object\":\"chat.completion\",\"created\":1731587836,\"model\":\"meta/llama-3.1-70b-instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"There once was a GPU so fine,\\nWhose computing power did truly shine.\\nIt processed with pace,\\nLarge datasets with ease and space,\\nAnd calculations that were truly divine.\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":23,\"total_tokens\":58,\"completion_tokens\":35}}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "\"$NIM_URL/v1/chat/completions\" \\\n",
    "-H 'accept: application/json' \\\n",
    "-H 'Content-Type: application/json' \\\n",
    "-d '{ \\\n",
    "    \"model\": \"meta/llama-3.1-70b-instruct\", \\\n",
    "    \"messages\": [{\"role\":\"user\", \"content\":\"Write a limerick about the wonders of GPU computing.\"}],\\\n",
    "    \"max_tokens\": 64 \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\":\"chat-c76b3d2c555f4d0cb6384230ab86cd0b\",\"object\":\"chat.completion\",\"created\":1731587746,\"model\":\"meta/llama-3.1-70b-instruct\",\"choices\":[{\"index\":0,\"message\":{\"role\":\"assistant\",\"content\":\"There once was a GPU so fine,\\nWhose computing power did truly shine.\\nIt processed with pace,\\nLarge datasets with ease and space,\\nAnd calculations that were truly divine.\"},\"logprobs\":null,\"finish_reason\":\"stop\",\"stop_reason\":null}],\"usage\":{\"prompt_tokens\":23,\"total_tokens\":58,\"completion_tokens\":35}}"
     ]
    }
   ],
   "source": [
    "!curl -X 'POST' \\\n",
    "'http://0.0.0.0:8000/v1/chat/completions' \\\n",
    "-H 'accept: application/json' \\\n",
    "-H 'Content-Type: application/json' \\\n",
    "-d '{ \\\n",
    "    \"model\": \"meta/llama-3.1-70b-instruct\", \\\n",
    "    \"messages\": [{\"role\":\"user\", \"content\":\"Write a limerick about the wonders of GPU computing.\"}], \\\n",
    "    \"max_tokens\": 64 \\\n",
    "}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCSx_UMG8lZ9"
   },
   "source": [
    "### OpenAI API interface 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p_EUitGGhOwo"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "q4MHZqK0hr6S"
   },
   "outputs": [],
   "source": [
    "client = OpenAI(base_url=\"{0}/v1\".format(os.environ[\"NIM_URL\"]), api_key=\"not-used\")\n",
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yhYUVPkrXZXu"
   },
   "outputs": [],
   "source": [
    "def chatbot(system_prompt):\n",
    "    print(\"NVIDIA NIM {0} 모델 챗봇에 오신 것을 환영합니다! (종료하려면 'quit'를 입력하세요)\".format(models.data[0].id))\n",
    "\n",
    "    # 대화 기록을 저장할 리스트\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}\n",
    "    ]\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"사용자: \")\n",
    "\n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"챗봇을 종료합니다. 감사합니다!\")\n",
    "            break\n",
    "\n",
    "        # 사용자 입력을 메시지 리스트에 추가\n",
    "        messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "        # GPT-4o API 호출\n",
    "        response = client.chat.completions.create(\n",
    "            model=models.data[0].id,\n",
    "            messages=messages,\n",
    "            temperature= 0.5,\n",
    "            top_p= 1,\n",
    "            max_tokens= 1024,\n",
    "        )\n",
    "\n",
    "        # 챗봇의 응답 출력\n",
    "        assistant_response = response.choices[0].message.content\n",
    "        print(\"챗봇:\", assistant_response)\n",
    "\n",
    "        # 챗봇의 응답을 메시지 리스트에 추가\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "4XspnUA6jKMm"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 전문적인 여행 가이드 챗봇입니다. 사용자에게 여행 정보와 조언을 제공하는 것이 당신의 역할입니다.\n",
    "\n",
    "사용자가 여행지, 날짜, 예산 등의 정보를 제공하면 그에 맞는 맞춤형 여행 계획을 제안해주세요. 관광 명소, 숙박 시설, 식당 등을 포함한 상세한 일정을 제공해야 합니다.\n",
    "\n",
    "응답은 다음 형식으로 제공하세요:\n",
    "1. 여행 개요 (2-3문장)\n",
    "2. 일일 일정 (날짜별로 구분)\n",
    "   - 오전 활동\n",
    "   - 점심 추천\n",
    "   - 오후 활동\n",
    "   - 저녁 추천\n",
    "3. 예상 비용\n",
    "4. 추가 팁\n",
    "\n",
    "사용자의 여행 스타일(모험, 문화체험, 휴식 등), 동반자 유형(가족, 커플, 친구 등), 특별한 요구사항(접근성, 식이 제한 등)을 고려하여 추천해주세요.\n",
    "\n",
    "사용자의 정보가 불충분하거나 불명확한 경우, 추가 질문을 통해 필요한 정보를 얻으세요. 예를 들어, \"여행 날짜를 알려주시면 더 정확한 정보를 제공할 수 있습니다.\"와 같이 요청하세요.\n",
    "\n",
    "대답은 한국어로 해줍니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36450,
     "status": "ok",
     "timestamp": 1721023674432,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "tZU5ZIynjRgC",
    "outputId": "d3277fab-1caf-4be1-9b49-9a9c1ef433cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA NIM meta/llama-3.1-70b-instruct 모델 챗봇에 오신 것을 환영합니다! (종료하려면 'quit'를 입력하세요)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  대한민국 서울에서 3박 4일 여행 일정을 짜줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇: 서울 여행을 계획중이시군요! 서울은 한국의 수도이자 문화, 역사, 패션, 음식 등 다양한 즐거움을 제공하는 도시입니다. 3박 4일 동안 서울을 즐길 수 있는 여행 일정을 추천해 드리겠습니다.\n",
      "\n",
      "**1. 여행 개요**\n",
      "\n",
      "서울의 대표적인 관광지와 문화 경험을 포함한 3박 4일 여행 일정을 준비했습니다. 이 일정은 역사와 문화, 쇼핑과 음식을 모두 포함하여 다양한 서울의 즐거움을 경험할 수 있습니다.\n",
      "\n",
      "**2. 일일 일정**\n",
      "\n",
      "### 1일차 (목요일)\n",
      "\n",
      "*   **오전 활동**: 경복궁 관람 (09:00 - 10:00) - 서울의 대표적인 궁궐인 경복궁을 방문하여 한국의 역사와 문화를 경험하세요.\n",
      "*   **점심 추천**: 광장시장에서 전통 한식을 맛보세요. (11:00 - 12:30) - 한국 전통시장의 분위기를 즐기면서 다양한 음식을 맛보실 수 있습니다.\n",
      "*   **오후 활동**: 명동 쇼핑과 관광 (13:00 - 16:00) - 명동은 쇼핑과 음식, 패션을 즐길 수 있는 대표적인 지역입니다. 명동성당, 명동거리, 남대문시장 등을 방문하세요.\n",
      "*   **저녁 추천**: 홍대앞에서 저녁 식사와 밤 문화를 즐기세요. (18:00 - 21:00) - 홍대앞은 젊은이들의 문화와 패션을 경험할 수 있는 곳입니다. 다양한 음식점과 카페, 클럽 등을 즐기실 수 있습니다.\n",
      "\n",
      "### 2일차 (금요일)\n",
      "\n",
      "*   **오전 활동**: Bukchon 한옥 마을 관람 (09:00 - 12:00) - 전통 한옥 마을을 산책하며 한국의 전통 건축과 문화를 경험하세요.\n",
      "*   **점심 추천**: 인사동에서 전통 한식을 맛보세요. (12:00 - 13:30) - 인사동은 한국 전통 문화와 예술을 경험할 수 있는 곳입니다. 다양한 전통 음식을 맛보실 수 있습니다.\n",
      "*   **오후 활동**: 청와대와 청와대 산책로 (14:00 - 17:00) - 청와대는 한국의 대통령 관저로 역사와 문화를 경험할 수 있습니다. 청와대 산책로는 아름다운 경치를 즐길 수 있는 곳입니다.\n",
      "*   **저녁 추천**: 이태원에서 국제 음식을 즐기세요. (18:00 - 21:00) - 이태원은 국제 음식과 문화를 경험할 수 있는 곳입니다. 다양한 음식점과 바 등을 즐기실 수 있습니다.\n",
      "\n",
      "### 3일차 (토요일)\n",
      "\n",
      "*   **오전 활동**: 남산 타워 (N 서울 타워) 방문 (09:00 - 12:00) - 남산 타워는 서울의 대표적인 랜드마크로 도시 전경을 즐길 수 있는 곳입니다.\n",
      "*   **점심 추천**: 명동에서 중식 한정을 맛보세요. (12:00 - 13:30) - 명동은 다양한 음식을 즐길 수 있는 곳입니다. 중식 한정을 맛보실 수 있습니다.\n",
      "*   **오후 활동**: 강남의 쇼핑과 엔터테인먼트 (14:00 - 18:00) - 강남은 패션과 엔터테인먼트를 즐길 수 있는 곳입니다. 강남역, 강남대로, COEX 등을 방문하세요.\n",
      "*   **저녁 추천**: 강남에서 저녁 식사와 밤 문화를 즐기세요. (19:00 - 22:00) - 강남은 다양한 음식점과 클럽, 바 등을 즐길 수 있는 곳입니다.\n",
      "\n",
      "### 4일차 (일요일)\n",
      "\n",
      "*   **오전 활동**: 종로에서 전통 문화를 경험하세요. (09:00 - 12:00) - 종로는 한국의 전통 문화를 경험할 수 있는 곳입니다. 종로길, 종로3가, 종로5가 등을 방문하세요.\n",
      "*   **점심 추천**: 광화문에서 점심 식사하세요. (12:00 - 13:30) - 광화문은 한국의 역사와 문화를 경험할 수 있는 곳입니다. 다양한 음식을 맛보실 수 있습니다.\n",
      "*   **오후 활동**: 서울역과 서울로 7017 (14:00 - 17:00) - 서울역은 한국의 대표적인 철도역으로 다양한 문화와 음식을 즐길 수 있습니다. 서울로 7017은 서울의 역사와 문화를 경험\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇을 종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "chatbot(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "yCbdkKwz9AxO"
   },
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "당신은 맛집 추천 전문 챗봇입니다. 사용자의 요구사항에 맞는 최적의 맛집을 추천해주세요. 다음 정보를 바탕으로 맛집을 추천해 주세요:\n",
    "\n",
    "1. 위치: [사용자가 지정한 지역]\n",
    "2. 음식 종류: [사용자가 선호하는 요리 스타일 또는 음식 종류]\n",
    "3. 가격대: [사용자의 예산 범위]\n",
    "4. 분위기: [사용자가 원하는 식당 분위기]\n",
    "5. 특별 요구사항: [예: 주차 가능, 반려동물 동반 가능, 단체 수용 가능 등]\n",
    "\n",
    "각 추천 맛집에 대해 다음 정보를 포함해 주세요:\n",
    "- 식당 이름\n",
    "- 주소\n",
    "- 대표 메뉴 (1-2개)\n",
    "- 가격대\n",
    "- 특징 또는 추천 이유 (1-2문장)\n",
    "\n",
    "3-5개의 맛집을 추천해 주시고, 각 추천에 대한 간단한 설명을 덧붙여 주세요. 사용자의 요구사항에 가장 잘 맞는 맛집부터 순서대로 나열해 주세요.\n",
    "\n",
    "마지막으로, 사용자에게 추가 정보나 다른 추천을 원하는지 물어보세요.\n",
    "대답은 한국어로 해줍니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60581,
     "status": "ok",
     "timestamp": 1721024532701,
     "user": {
      "displayName": "Gwangsoo Hong KR",
      "userId": "10691790583367714658"
     },
     "user_tz": -540
    },
    "id": "tiJXtCeQDE_d",
    "outputId": "388d75e6-6589-4dc7-d6e7-9fbb7e24b4db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA NIM meta/llama-3.1-70b-instruct 모델 챗봇에 오신 것을 환영합니다! (종료하려면 'quit'를 입력하세요)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  대한민국 광주 광산구에서 맛집을 추천해줘\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇: 광주 광산구 맛집을 추천해드리겠습니다!\n",
      "\n",
      "1.  **식당 이름:** 상무대통갈비 **주소:** 광주광역시 광산구 상무대로 155 **대표 메뉴:** 대통갈비, 양념돼지목살 **가격대:** 1만원대 **특징:** 대통갈비는 상무대통갈비의 대표 메뉴로, 양념이 잘 베어있고 부드러운 식감이 특징입니다. 양념돼지목살도 맛있기로 유명합니다.\n",
      "\n",
      "2.  **식당 이름:** 광주광역시 광산구 신가도시로 15 **주소:** 광주광역시 광산구 신가도시로 15 **대표 메뉴:** 삼겹살, 목살 **가격대:** 1만 원대 **특징:** 삼겹살과 목살이 유명한 집입니다. 고기가 تازه하고 양이 많아 만족도 높은 맛집입니다.\n",
      "\n",
      "3.  **식당 이름:** 광주광역시 광산구 상무대로 169 **주소:** 광주광역시 광산구 상무대로 169 **대표 메뉴:** 소불고기, 닭불고기 **가격대:** 1만 원대 **특징:** 소불고기와 닭불고기가 유명한 집입니다. 고기가 تازه하고 양이 많아 만족도 높은 맛집입니다.\n",
      "\n",
      "4.  **식당 이름:** 광주광역시 광산구 신가도시로 20 **주소:** 광주광역시 광산구 신가도시로 20 **대표 메뉴:** 한우불고기, 한우등심 **가격대:** 2만 원대 **특징:** 한우불고기와 한우등심이 유명한 집입니다. 고기가 질이 좋고 양이 많아 만족도 높은 맛집입니다.\n",
      "\n",
      "5.  **식당 이름:** 광주광역시 광산구 상무대로 173 **주소:** 광주광역시 광산구 상무대로 173 **대표 메뉴:** 삼겹살, 목살 **가격대:** 1만 원대 **특징:** 삼겹살과 목살이 유명한 집입니다. 고기가 تازه하고 양이 많아 만족도 높은 맛집입니다.\n",
      "\n",
      "이 중에서 어떤 음식이 맛있어 보이나요? 혹시 다른 지역이나 음식 종류를 원하시면 언제든지 물어봐 주세요!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "사용자:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "챗봇을 종료합니다. 감사합니다!\n"
     ]
    }
   ],
   "source": [
    "chatbot(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kSQnn4saDGvX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a limerick about GPU computing:\n",
      "\n",
      "There once was a GPU so fine,\n",
      "Whose parallel processing was divine.\n",
      "It crunched with great zest,\n",
      "Through data at rest,\n",
      "And made complex tasks truly shine."
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"meta/llama-3.1-405b-instruct\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm of computing, where data's the king,\n",
      "GPU power makes everything sing.\n",
      "Parallel processing, so neat,\n",
      "Makes complex tasks a treat,\n",
      "A wonder of tech, it's truly a thing!\n",
      "\n",
      "With thousands of cores, in silicon etched,\n",
      "Through machine learning, they're well-matched.\n",
      "Images, videos, they render,\n",
      "In scientific research, they're a lender,\n",
      "GPU computing, a marvel, is hatched.\n",
      "\n",
      "So here's to the GPU, in its glory,\n",
      "Telling stories of speed, not just lore.\n",
      "In every pixel, every frame,\n",
      "It plays a part in the game,\n",
      "A silent hero, forever we'll adore.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url = \"https://integrate.api.nvidia.com/v1\",\n",
    "  api_key = \"\"\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"nvidia/nemotron-4-340b-instruct\",\n",
    "  messages=[{\"role\":\"user\",\"content\":\"Write a limerick about the wonders of GPU computing.\"}],\n",
    "  temperature=0.2,\n",
    "  top_p=0.7,\n",
    "  max_tokens=1024,\n",
    "  stream=True\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "  if chunk.choices[0].delta.content is not None:\n",
    "    print(chunk.choices[0].delta.content, end=\"\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMzxmBzz//RRF1WgO4ZS5xQ",
   "provenance": [
    {
     "file_id": "1KdsI5tQdlH0RLEd2ojGhX6Ao3OqMxYKx",
     "timestamp": 1721021419964
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
