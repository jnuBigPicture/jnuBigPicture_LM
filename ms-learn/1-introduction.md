# PyTorch를 활용한 자연어 처리 소개

이 모듈에서는 자연어 텍스트를 처리하기 위한 다양한 신경망 아키텍처를 살펴보겠습니다. 최근 몇 년 동안 **자연어 처리**(NLP) 분야는 빠르게 성장해 왔습니다. 언어 모델의 성능은 텍스트를 "이해"하는 전반적인 능력에 달려 있으며, 대규모 텍스트 코퍼스를 기반으로 비지도 학습이 가능하기 때문입니다. 따라서 BERT와 같은 사전 학습된 텍스트 모델은 많은 NLP 작업을 간소화하고 성능을 획기적으로 향상시켰습니다.

PyTorch에서 NLP를 텐서로 표현하는 기본적인 측면과 Bag-of-Words, 임베딩, 순환 신경망 등의 고전적인 NLP 아키텍처에 초점을 맞출 것입니다.

## 자연어어 Tasks

전통적으로 신경망을 사용하여 해결하려는 여러 NLP 작업이 있습니다.
* **텍스트 분류**는 텍스트 조각을 미리 정의된 여러 클래스 중 하나로 분류해야 할 때 사용됩니다. 이메일 스팸 감지, 뉴스 분류, 지원 요청을 특정 카테고리에 할당하는 것 등이 여기에 해당합니다.
* **의도 분류**는 대화형 AI 시스템의 입력 발화를 구문의 실제 의미 또는 사용자의 의도를 나타내는 의도 중 하나에 매핑하는 텍스트 분류의 한 가지 구체적인 사례입니다.
* **감정 분석**은 주어진 텍스트의 부정성 정도를 파악하는 회귀 작업입니다. 데이터세트의 텍스트에 가장 부정적인 것(-1)부터 가장 긍정적인 것(+1)까지 레이블을 지정하고, 텍스트의 "긍정성" 수치를 출력하는 모델을 학습시킬 수 있습니다.
* **명명된 개체 인식**(NER)은 텍스트에서 날짜, 주소, 사람 이름 등과 같은 개체를 추출하는 작업입니다. 의도 분류와 함께 NER은 대화 시스템에서 사용자 발화에서 매개변수를 추출하는 데 자주 사용됩니다.
* **키워드 추출**과 유사한 작업을 통해 텍스트 내에서 가장 의미 있는 단어를 찾아 태그로 사용할 수 있습니다.
* **텍스트 요약**은 가장 의미 있는 텍스트 조각을 추출하여 사용자에게 대부분의 의미를 포함하는 압축된 버전을 제공합니다.
* **질의응답**은 텍스트 조각에서 답변을 추출하는 작업입니다. 이 모델은 텍스트 조각과 질문을 입력으로 받고, 텍스트 내에서 답변이 포함된 정확한 위치를 찾아야 합니다. 예를 들어, "*John은 Microsoft Learn을 좋아하는 22세 학생입니다*"라는 텍스트와 *John의 나이는 몇 살입니까*라는 질문을 입력하면 답은 *22*가 됩니다.

이 모듈에서는 주로 **텍스트 분류** 작업에 중점을 둘 것입니다. 하지만 앞으로 더 어려운 작업을 처리하는 데 필요한 모든 중요한 개념을 배울 것입니다.

# 학습 목표
- NLP 작업을 위해 텍스트가 처리되는 방식을 이해합니다.
- 순환 신경망(RNN)과 생성 신경망(GNN) 소개
- 주의 메커니즘에 대해 알아봅니다.
- 텍스트 분류 모델을 구축하는 방법을 알아봅니다.

# 선수과목

- 파이썬 지식
- 머신러닝 기본 이해